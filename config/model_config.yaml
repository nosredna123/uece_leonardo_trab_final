# Transit Coverage Classifier Configuration
# Based on Phase 0 research findings from research.md

# Geographic Grid Configuration
grid:
  # Cell size in meters (250m balances resolution and aggregation)
  cell_size_meters: 250
  
  # Geographic bounds for Belo Horizonte (from research)
  # Bounds include 2km buffer around GTFS stop coverage
  bounds:
    lat_min: -20.046411
    lat_max: -19.758246
    lon_min: -44.081380
    lon_max: -43.843522
  
  # Expected grid statistics (validation targets)
  expected_cells: 13000  # Approximate cell count for 250m grids
  expected_area_km2: 0.0625  # Expected area per cell (0.25km × 0.25km)

# Feature Extraction Configuration
features:
  # Feature weights for composite score calculation
  # Weights must sum to 1.0
  stop_count_weight: 0.4
  route_count_weight: 0.3
  daily_trips_weight: 0.3
  
  # Feature normalization
  normalization_method: "StandardScaler"  # z-score normalization (mean=0, std=1)
  
  # Optional metrics
  include_density: true  # Calculate stop_density (stops/km²)
  include_diversity: true  # Calculate route_diversity

# Label Generation Configuration
labels:
  # Threshold for well-served classification
  # For 250m grids: use 75th percentile for balanced classes
  # Top 25% (75th percentile) = well-served
  threshold_quantile: 0.75
  
  # Minimum minority class percentage (validation)
  min_minority_class_pct: 0.15
  
  # Target label distribution
  target_well_served_pct: 0.30  # 30% well-served cells
  target_underserved_pct: 0.70  # 70% underserved cells

# Training Configuration
training:
  # Random seed for reproducibility
  random_seed: 42
  
  # Train/validation/test split ratios
  test_size: 0.15  # 15% for test set
  val_size: 0.15   # 15% for validation set (from remaining after test split)
  # Train size: 70% (calculated as remainder)
  
  # Cross-validation folds
  cv_folds: 5  # Can be reduced to 3 if training time exceeds 30 minutes
  
  # Stratification
  stratify: true  # Maintain class balance in splits
  
  # Parallel processing
  n_jobs: -1  # Use all available CPU cores

# Model Hyperparameter Search Spaces
models:
  # Logistic Regression - GridSearchCV (fast, exhaustive)
  logistic_regression:
    search_method: "grid"
    param_grid:
      C: [0.01, 0.1, 1.0, 10.0]
      penalty: ["l2"]
      max_iter: [1000]
      solver: ["lbfgs"]
  
  # Random Forest - RandomizedSearchCV (efficient for large space)
  random_forest:
    search_method: "randomized"
    n_iter: 20  # Number of random combinations to try
    param_distributions:
      n_estimators: [100, 150, 200, 300, 500]
      max_depth: [10, 15, 20, 25, null]  # null = no limit
      min_samples_split: [2, 5, 10, 15]
      min_samples_leaf: [1, 2, 4]
      max_features: ["sqrt", "log2"]
      bootstrap: [true]
  
  # Gradient Boosting - RandomizedSearchCV
  gradient_boosting:
    search_method: "randomized"
    n_iter: 15  # Number of random combinations to try
    param_distributions:
      n_estimators: [100, 150, 200, 250]
      learning_rate: [0.01, 0.05, 0.1, 0.15]
      max_depth: [3, 4, 5, 6, 7]
      subsample: [0.8, 0.9, 1.0]
      min_samples_split: [2, 5, 10]
      min_samples_leaf: [1, 2, 4]

# Evaluation Configuration
evaluation:
  # Metrics to calculate and report
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "roc_auc"
  
  # Minimum F1-score threshold for success
  min_f1_threshold: 0.70
  
  # Scoring metric for model selection
  selection_metric: "f1"
  
  # Visualizations to generate
  generate_confusion_matrix: true
  generate_roc_curves: true
  generate_feature_importance: true

# Model Export Configuration
export:
  # ONNX export settings
  onnx:
    opset_version: 15  # ONNX operator set version
    max_file_size_mb: 100  # Maximum allowed file size
  
  # Model metadata to save
  metadata:
    include_feature_names: true
    include_model_version: true
    include_training_date: true
    include_performance_metrics: true

# API Configuration (for Phase 10, optional)
api:
  # Performance targets
  single_prediction_latency_ms: 200  # Maximum latency for single prediction
  batch_prediction_latency_ms: 5000  # Maximum latency for 100 predictions
  
  # Model loading
  use_onnx: true  # Use ONNX runtime for inference
  
  # Endpoints
  enable_health_check: true
  enable_batch_predictions: true

# Pipeline Configuration
pipeline:
  # Directory paths (relative to project root)
  data_dir: "data"
  processed_dir: "data/processed"
  models_dir: "models/transit_coverage"
  reports_dir: "reports"
  
  # Performance targets
  feature_extraction_max_minutes: 5
  training_max_minutes: 40  # Target: 30 minutes
  
  # Validation
  validate_intermediate_outputs: true
  save_intermediate_artifacts: true

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  save_to_file: true
  log_file: "logs/pipeline.log"
