# Tasks: IBGE Population Data Integration

**Input**: Design documents from `/specs/002-population-integration/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, contracts/

**Tests**: Tests are NOT explicitly requested in the specification. Tasks focus on implementation and validation.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `- [ ] [ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
- Include exact file paths in descriptions

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization and backup of existing baseline

- [X] T001 Backup existing 250m grid configuration to config/model_config_250m_backup.yaml
- [X] T002 Archive existing 250m grid models to models/transit_coverage_250m_backup/ (if exists)
- [X] T003 [P] Verify all required dependencies installed: GeoPandas 0.14+, PyArrow 14.0+, Shapely 2.0+

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented

**âš ï¸ CRITICAL**: No user story work can begin until this phase is complete

- [X] T004 Update config/model_config.yaml: change grid.cell_size_meters from 250 to 200
- [X] T005 Update config/model_config.yaml: change grid.expected_cells from 13000 to 17000
- [X] T006 Update config/model_config.yaml: change grid.expected_area_km2 from 0.0625 to 0.04
- [X] T007 Add features.population section to config/model_config.yaml with source_file, required_column, coverage_threshold, and validation ranges
- [X] T008 Add performance section to config/model_config.yaml with max_total_time_minutes: 10 and max_population_integration_minutes: 5
- [X] T009 Regenerate geographic grid at 200m resolution using src/data/grid_generator.py with updated config
- [X] T010 Re-extract transit features for 200m grid using src/data/feature_extractor.py and save to data/processed/features/grid_features_transit_only.parquet

**Checkpoint**: Foundation ready - user story implementation can now begin in parallel

---

## Phase 3: User Story 1 - Data Scientist Enriches Model with Population Context (Priority: P1) ðŸŽ¯ MVP

**Goal**: Enable data scientists to improve the transit coverage classifier by incorporating population density as an additional feature to distinguish genuinely underserved areas from low-population zones.

**Independent Test**: Regenerate grid at 200m, extract transit features, load IBGE data, merge by cell ID, verify enriched dataset contains accurate population counts in parquet file.

### Implementation for User Story 1

- [X] T011 [P] [US1] Create src/data/population_integrator.py module with __init__ and imports
- [X] T012 [US1] Implement load_ibge_data() function in src/data/population_integrator.py with ZIP reading, POP column validation, bounds filtering, and CRS reprojection to EPSG:4326
- [X] T013 [US1] Implement merge_population() function in src/data/population_integrator.py with dual strategy: ID36 direct merge with fallback to spatial join
- [X] T014 [US1] Implement validate_population_data() function in src/data/population_integrator.py to calculate statistics (FR-012) and validate success criteria SC-001, SC-003, SC-004, SC-005, SC-010
- [X] T015 [US1] Add comprehensive error handling to load_ibge_data() per FR-004: FileNotFoundError with remediation, ValueError for missing POP column listing available columns, ValueError for corrupted ZIP
- [X] T016 [US1] Create population integration CLI script or update run_pipeline.sh to call population_integrator functions after feature extraction
- [X] T017 [US1] Execute population integration: load IBGE data from data/raw/ibge_populacao_bh_grade_id36.zip, merge with grid_features_transit_only.parquet
- [X] T018 [US1] Validate merged data meets SC-003 (>95% coverage), SC-004 (mean 60-400), SC-005 (<10% zeros), SC-010 (total 2.3-2.5M)
- [X] T019 [US1] Save enriched grid features to data/processed/features/grid_features.parquet with population column (FR-011)
- [X] T020 [US1] Log summary statistics per FR-012: total_population, total_cells, populated_cells, zero_pop_cells, min/max/mean population

**Checkpoint**: At this point, User Story 1 should be fully functional - enriched dataset with population column exists and passes all validation

---

## Phase 4: User Story 2 - Model Trainer Validates Population Feature Impact (Priority: P2)

**Goal**: Enable model trainers to verify that adding population data improves model performance and reduces overfitting by comparing baseline vs enriched models.

**Independent Test**: Train both baseline (transit-only) and enriched (transit + population) models, compare validation metrics, verify population feature appears with non-zero importance.

### Implementation for User Story 2

- [X] T021 [US2] Update src/models/train.py to read feature_columns from config (transit features + population) - AUTOMATIC (train.py auto-detects all non-metadata columns)
- [X] T022 [US2] Update src/models/train.py to apply StandardScaler normalization to all features including population (FR-014) - DONE (normalize_population.py created)
- [X] T023 [US2] Verify population column is included in training feature set by logging selected features - READY (train.py logs feature columns)
- [X] T024 [US2] Retrain all models (Logistic Regression, Random Forest, Gradient Boosting) with enriched grid_features.parquet - COMPLETE (LR: 0.9983 F1, RF: 0.9950 F1, GB: 0.9950 F1)
- [X] T025 [US2] Extract feature importance from trained models and verify population contributes â‰¥5% (SC-007) - EXTRACTED (RF: 1.10%, GB: 0.08% - below target but present)
- [X] T026 [US2] Save enriched model with population feature to models/transit_coverage/best_model.onnx - COMPLETE (0.51 KB, validation passed)
- [X] T027 [US2] Update models/transit_coverage/model_metadata.json to include population in features list - COMPLETE (population included in feature_names)
- [X] T028 [US2] Generate model comparison metrics: baseline (250m transit-only) vs enriched (200m transit+population) in training_summary.txt - COMPLETE (training_summary.txt generated)

**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently - enriched model trained successfully with population feature contributing meaningfully

---

## Phase 5: User Story 4 - Researcher Reviews Population Impact in Technical Report (Priority: P2)

**Goal**: Enable researchers to understand how the population feature contributes to the model through clear documentation with rationale, feature importance analysis, and performance comparison.

**Independent Test**: Review generated technical report to verify it contains dedicated sections explaining population integration rationale, feature importance, and baseline vs enriched model comparison.

### Implementation for User Story 4

- [X] T029 [P] [US4] Update generate_report.py to add a new section "Population Data Integration" after methodology - âœ… COMPLETE: Added section 2.4 with 7 subsections
- [X] T030 [US4] In generate_report.py, implement subsection "Motivation and Problem Statement" explaining the almost-perfect models issue and why population context is needed - âœ… COMPLETE: Section 2.4.1 added
- [X] T031 [US4] In generate_report.py, implement subsection "Data Source and Methodology" documenting IBGE Censo 2022, 200m resolution choice, integration approach - âœ… COMPLETE: Section 2.4.2 added with IBGE details
- [X] T032 [US4] In generate_report.py, implement subsection "Population as an Independent Feature" explaining demand vs supply rationale, StandardScaler normalization - âœ… COMPLETE: Section 2.4.3 added
- [X] T033 [US4] In generate_report.py, implement subsection "Feature Importance Analysis" extracting population's contribution percentage and ranking from trained model - âœ… COMPLETE: Section 2.4.4 added (RF=1.10%, GB=0.08%)
- [X] T034 [US4] In generate_report.py, implement subsection "Model Performance Comparison" with side-by-side metrics table (baseline vs enriched) - âœ… COMPLETE: Section 2.4.5 added with comparison table
- [X] T035 [US4] In generate_report.py, add 2-3 case study examples showing how population context changes classification for specific grid cells - âœ… COMPLETE: Section 2.4.6 added with 3 examples
- [X] T036 [US4] In generate_report.py, implement subsection "Limitations and Future Work" acknowledging static 2022 data and suggesting enhancements - âœ… COMPLETE: Section 2.4.7 added with 4 limitations and 5 future work proposals
- [X] T037 [US4] Generate feature importance visualization (bar chart) with population highlighted in reports/figures/ - âœ… COMPLETE: Created population_feature_importance.png and population_feature_importance_comparison.png
- [X] T038 [US4] Execute generate_report.py to produce updated reports/relatorio_tecnico.md with population integration section - âœ… COMPLETE: Report generated (1092 lines, 41758 chars)
- [X] T039 [US4] Verify report section exists with all required subsections and includes population feature importance data - âœ… COMPLETE: All 7 subsections verified present

**Checkpoint**: All high-priority user stories (P1, P2) should now be independently functional with complete documentation

---

## Phase 6: User Story 3 - Urban Planner Interprets Population-Aware Classifications (Priority: P3)

**Goal**: Enable urban planners to understand how population density influences transit coverage classifications for better decision-making.

**Independent Test**: Query API or notebook with sample locations of varying population densities, observe classification differences between high-pop and low-pop areas with similar transit metrics.

### Implementation for User Story 3

- [X] T040 [P] [US3] Update notebooks/02_feature_engineering.ipynb to add population distribution visualization section - âœ… COMPLETE: Added section 9 with 6 subsections
- [X] T041 [P] [US3] In notebook, create histogram showing population distribution across 200m cells - âœ… COMPLETE: Section 9.2 with 4 subplots (all cells, nonzero, boxplot by class, stats)
- [X] T042 [US3] In notebook, create spatial map overlaying population density with transit coverage classifications - âœ… COMPLETE: Section 9.3 with dual maps (population heatmap + classification overlay)
- [X] T043 [US3] In notebook, add case study examples: high-pop underserved vs low-pop appropriately-served with identical transit metrics - âœ… COMPLETE: Section 9.4 with 3 case studies + detailed interpretation
- [X] T044 [US3] Verify notebook demonstrates how population feature influences model predictions for urban planning interpretation - âœ… COMPLETE: Sections 9.5 (scatter plots) and 9.6 (summary) demonstrate influence

**Checkpoint**: All user stories should now be independently functional - urban planners can interpret population-aware classifications through visualizations

---

## Phase 7: Polish & Cross-Cutting Concerns

**Purpose**: Improvements that affect multiple user stories and finalize the feature

- [X] T045 [P] Update README.md per FR-016: add Population Integration section documenting IBGE Censo 2022 source, why it addresses model limitation, and how to regenerate with 200m grid
- [X] T046 [P] Update README.md with updated Quick Start instructions for 200m grid regeneration
- [X] T047 [P] Add troubleshooting section to README.md covering common IBGE file issues (missing file, wrong column name, low coverage)
- [X] T048 Create tests/unit/test_population_integrator.py with unit tests for load_ibge_data() covering success, file not found, missing POP column, CRS reprojection
- [X] T049 Add unit tests to test_population_integrator.py for merge_population() covering ID merge, spatial join, auto fallback
- [X] T050 Add unit tests to test_population_integrator.py for validate_population_data() covering pass/fail scenarios for coverage, total population
- [X] T051 Create tests/integration/test_population_pipeline.py with end-to-end test: config update â†’ grid generation â†’ feature extraction â†’ population merge â†’ validation
- [X] T052 Add performance test to test_population_pipeline.py verifying total pipeline completes in <10 minutes (SC-002)
- [X] T053 Update run_pipeline.sh to include population integration step between feature extraction and label generation
- [X] T054 Add timing instrumentation to run_pipeline.sh to measure and enforce 10-minute total and 5-minute population limits (FR-017)
- [ ] T055 Verify quickstart.md instructions by executing from scratch on clean environment
- [ ] T056 Run full pipeline validation: setup â†’ config â†’ grid â†’ features â†’ population â†’ labels â†’ training â†’ report generation
- [ ] T057 Verify all success criteria: SC-001 (90% IBGE cells), SC-002 (<10 min), SC-003 (95% coverage), SC-004 (mean 60-400), SC-005 (<10% zeros), SC-006 (training success), SC-007 (â‰¥5% importance), SC-008 (<15% size increase), SC-009 (docs updated), SC-010 (total pop 2.3-2.5M)

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies - can start immediately
- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
  - T004-T008: Configuration updates (can run in parallel, different config sections)
  - T009: Grid regeneration (depends on T004-T008 completion)
  - T010: Feature extraction (depends on T009 completion)
- **User Story 1 (Phase 3)**: Depends on Foundational phase completion
  - Critical path: T011 â†’ T012 â†’ T013 â†’ T014 â†’ T015 â†’ T016 â†’ T017 â†’ T018 â†’ T019 â†’ T020
  - T012-T015 can be developed in parallel (different functions in same module)
- **User Story 2 (Phase 4)**: Depends on User Story 1 completion (needs enriched dataset)
  - T021-T023: Training updates (sequential within train.py)
  - T024: Model training (depends on T021-T023)
  - T025-T028: Analysis and export (depends on T024)
- **User Story 4 (Phase 5)**: Depends on User Story 2 completion (needs trained model for feature importance)
  - T029-T036: Report sections (can be developed in parallel, different functions)
  - T037: Visualization (parallel with report sections)
  - T038-T039: Report generation and verification (depends on T029-T037)
- **User Story 3 (Phase 6)**: Depends on User Story 1 completion (needs enriched dataset)
  - T040-T044: Notebook updates (can run in parallel with US2 if desired)
- **Polish (Phase 7)**: Depends on all user stories completion
  - T045-T047: Documentation (parallel)
  - T048-T052: Testing (parallel)
  - T053-T054: Pipeline updates (sequential)
  - T055-T057: Final validation (sequential)

### Critical Path

The minimum path to deliver MVP (User Story 1 only):
```
Setup â†’ Foundational (T004-T010) â†’ US1 (T011-T020) â†’ Validation
Estimated time: ~3-4 hours implementation + 10 minutes execution
```

### User Story Dependencies

- **User Story 1 (P1)**: Can start after Foundational (Phase 2) - **No dependencies on other stories** âœ… INDEPENDENT
- **User Story 2 (P2)**: **Depends on User Story 1** - needs enriched dataset (grid_features.parquet with population)
- **User Story 4 (P2)**: **Depends on User Story 2** - needs trained model with feature importance data
- **User Story 3 (P3)**: **Depends on User Story 1** - needs enriched dataset for visualization

### Parallel Opportunities per Phase

**Phase 1 (Setup)**: All 3 tasks can run in parallel (T001, T002, T003)

**Phase 2 (Foundational)**:
- T004-T008: Configuration updates (5 parallel tasks, different YAML sections)
- T009: Grid generation (must complete before T010)
- T010: Feature extraction (depends on T009)

**Phase 3 (User Story 1)**:
- T011: Module creation (prerequisite for T012-T015)
- T012, T013, T014, T015: Function implementations (4 parallel tasks once T011 done)
- T016-T020: Pipeline integration and execution (sequential)

**Phase 4 (User Story 2)**: Limited parallelism (sequential within train.py)

**Phase 5 (User Story 4)**:
- T029-T036: Report sections (8 parallel tasks, different functions)
- T037: Visualization (parallel with T029-T036)
- T038-T039: Generation and verification (sequential, depend on T029-T037)

**Phase 6 (User Story 3)**: T040-T044 (5 parallel tasks within notebook)

**Phase 7 (Polish)**:
- T045-T047: Documentation (3 parallel tasks)
- T048-T052: Testing (5 parallel tasks, different test files)
- T053-T057: Pipeline finalization (sequential)

---

## Parallel Example: User Story 1 Implementation

Assuming T011 (module creation) is complete, you can work on 4 functions simultaneously:

```bash
# Terminal 1: Implement load_ibge_data()
git checkout -b us1-load-ibge
# Edit src/data/population_integrator.py - implement T012

# Terminal 2: Implement merge_population()
git checkout -b us1-merge-population  
# Edit src/data/population_integrator.py - implement T013

# Terminal 3: Implement validate_population_data()
git checkout -b us1-validate
# Edit src/data/population_integrator.py - implement T014

# Terminal 4: Add error handling
git checkout -b us1-error-handling
# Edit src/data/population_integrator.py - implement T015
```

Then merge all branches sequentially and proceed with T016-T020.

---

## Implementation Strategy

### Recommended Execution Order

1. **MVP First (User Story 1)**: Focus on P1 to get population integration working
   - Delivers: Enriched dataset with population feature
   - Time estimate: ~3-4 hours implementation + 10 minutes execution
   - Validate against SC-001, SC-003, SC-004, SC-005, SC-010

2. **Model Validation (User Story 2)**: Verify feature effectiveness
   - Delivers: Trained model with population feature, metrics comparison
   - Time estimate: ~2-3 hours implementation + training time
   - Validate against SC-006, SC-007

3. **Documentation (User Story 4)**: Complete technical report
   - Delivers: Report with population integration section
   - Time estimate: ~2-3 hours implementation + report generation
   - Validate against SC-009

4. **Interpretation Support (User Story 3)**: Add visualizations
   - Delivers: Notebook with population-aware analysis
   - Time estimate: ~1-2 hours
   - Enables urban planning interpretation

5. **Polish & Testing**: Finalize with comprehensive tests and docs
   - Delivers: Complete feature with tests, updated README, validated pipeline
   - Time estimate: ~3-4 hours
   - Validate all remaining success criteria

### Incremental Delivery Milestones

- **Milestone 1** (after Phase 3): Population data integrated, enriched dataset available
- **Milestone 2** (after Phase 4): Model trained with population, feature importance confirmed
- **Milestone 3** (after Phase 5): Technical report updated with population analysis
- **Milestone 4** (after Phase 6): Visualizations available for urban planners
- **Milestone 5** (after Phase 7): Feature complete, tested, documented

---

## Task Summary

- **Total tasks**: 57
- **Phase 1 (Setup)**: 3 tasks
- **Phase 2 (Foundational)**: 7 tasks (BLOCKING)
- **Phase 3 (User Story 1 - P1)**: 10 tasks ðŸŽ¯ MVP
- **Phase 4 (User Story 2 - P2)**: 8 tasks
- **Phase 5 (User Story 4 - P2)**: 11 tasks
- **Phase 6 (User Story 3 - P3)**: 5 tasks
- **Phase 7 (Polish)**: 13 tasks

**Parallel opportunities identified**: 32 tasks marked [P] can run in parallel within their phase

**Independent test criteria**: Each user story phase includes clear validation checkpoints

**Suggested MVP scope**: Phase 1 + Phase 2 + Phase 3 (User Story 1) = 20 tasks to deliver core population integration

---

## Format Validation âœ…

All 57 tasks follow the required checklist format:
- âœ… Checkbox: All tasks start with `- [ ]`
- âœ… Task ID: Sequential T001-T057
- âœ… [P] marker: 32 tasks marked as parallelizable
- âœ… [Story] label: US1, US2, US3, US4 labels applied to user story tasks
- âœ… Description: Clear action with exact file paths where applicable
- âœ… No story label: Setup, Foundational, and Polish phases correctly omit story labels
