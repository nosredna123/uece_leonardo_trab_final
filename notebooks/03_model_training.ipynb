{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f98807",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fdd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from src.models.train import ModelTrainer\n",
    "from src.models.export import export_sklearn_to_onnx, export_model_joblib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce969b76",
   "metadata": {},
   "source": [
    "## 2. Carregar Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fece76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados processados\n",
    "processed_dir = Path('../data/processed')\n",
    "\n",
    "X_train = np.load(processed_dir / 'X_train.npy')\n",
    "X_test = np.load(processed_dir / 'X_test.npy')\n",
    "y_train = np.load(processed_dir / 'y_train.npy')\n",
    "y_test = np.load(processed_dir / 'y_test.npy')\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2150b",
   "metadata": {},
   "source": [
    "## 3. Inicializar ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05509c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(models_dir='../models')\n",
    "trainer.initialize_models()\n",
    "\n",
    "print(\"Modelos disponíveis:\")\n",
    "for model_name in trainer.models.keys():\n",
    "    print(f\"  - {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678be4b",
   "metadata": {},
   "source": [
    "## 4. Treinar Todos os Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dea003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar todos os modelos\n",
    "trainer.train_all_models(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c4de56",
   "metadata": {},
   "source": [
    "## 5. Comparar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b42571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame(trainer.results).T\n",
    "results_df = results_df.round(4)\n",
    "print(\"\\nResultados dos Modelos:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a2c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparação\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy\n",
    "results_df[['train_accuracy', 'test_accuracy']].plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Accuracy - Train vs Test')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Model')\n",
    "axes[0].legend(['Train', 'Test'])\n",
    "axes[0].set_ylim([0, 1.1])\n",
    "\n",
    "# Métricas de Test\n",
    "results_df[['test_precision', 'test_recall', 'test_f1']].plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Test Metrics Comparison')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_xlabel('Model')\n",
    "axes[1].legend(['Precision', 'Recall', 'F1-Score'])\n",
    "axes[1].set_ylim([0, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877479e",
   "metadata": {},
   "source": [
    "## 6. Otimização de Hiperparâmetros (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c469c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: Tuning para Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Descomentar para executar (pode demorar)\n",
    "# best_params, best_score = trainer.hyperparameter_tuning(\n",
    "#     'random_forest', \n",
    "#     param_grid, \n",
    "#     X_train, \n",
    "#     y_train, \n",
    "#     cv=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c690e",
   "metadata": {},
   "source": [
    "## 7. Salvar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ec6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar todos os modelos treinados\n",
    "for model_name in trainer.models.keys():\n",
    "    trainer.save_model(model_name)\n",
    "\n",
    "# Salvar resultados\n",
    "trainer.save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb41c3d",
   "metadata": {},
   "source": [
    "## 8. Exportar Melhor Modelo para ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter melhor modelo\n",
    "best_model_name, best_model = trainer.best_model\n",
    "print(f\"Melhor modelo: {best_model_name}\")\n",
    "\n",
    "# Exportar para ONNX\n",
    "X_sample = pd.DataFrame(X_train[:5])  # Amostra para inferência de forma\n",
    "\n",
    "try:\n",
    "    onnx_path = export_sklearn_to_onnx(\n",
    "        best_model,\n",
    "        X_sample,\n",
    "        output_path='../models',\n",
    "        model_name='best_model'\n",
    "    )\n",
    "    print(f\"\\nModelo exportado para: {onnx_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao exportar para ONNX: {e}\")\n",
    "    print(\"Salvando com joblib como alternativa...\")\n",
    "    export_model_joblib(best_model, '../models', 'best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff4117",
   "metadata": {},
   "source": [
    "## 9. Testar Modelo ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar modelo ONNX\n",
    "try:\n",
    "    import onnxruntime as rt\n",
    "    \n",
    "    # Carregar modelo ONNX\n",
    "    onnx_path = '../models/best_model.onnx'\n",
    "    sess = rt.InferenceSession(onnx_path)\n",
    "    \n",
    "    # Fazer predições\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    predictions = sess.run(None, {input_name: X_test[:5].astype(np.float32)})[0]\n",
    "    \n",
    "    print(\"Predições ONNX (primeiras 5):\")\n",
    "    print(predictions)\n",
    "    print(f\"\\nLabels reais (primeiras 5):\")\n",
    "    print(y_test[:5])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao testar modelo ONNX: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd7ce48",
   "metadata": {},
   "source": [
    "## 10. Conclusões\n",
    "\n",
    "TODO: Adicionar conclusões:\n",
    "- Melhor modelo e justificativa\n",
    "- Comparação de desempenho\n",
    "- Possíveis melhorias\n",
    "- Próximos passos"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
